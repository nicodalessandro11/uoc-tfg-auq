# ğŸ§  NLP Model with SQL Database Integration

This project implements a Natural Language Processing (NLP) agent using [LangChain](https://github.com/langchain-ai/langchain) and [Ollama](https://ollama.com) to translate natural language questions into SQL queries and execute them on a PostgreSQL database hosted in Supabase.

## ğŸš€ Features

- âœ… Local LLaMA 3B model running via Ollama (no cloud token needed)
- âœ… PostgreSQL database integration (via Supabase)
- âœ… LangChain agent powered by SQL toolkit
- âœ… Custom prompt for domain-specific query generation (urban & demographic data)

## ğŸ“‹ Prerequisites

- Python 3.11+
- [Ollama](https://ollama.com/) installed (`brew install ollama`)
- Supabase PostgreSQL database URI
- Make (optional, but recommended for command shortcuts)

## ğŸ”§ Setup

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd nlp-model
   ```

2. **Create the `.env` file**:
   ```bash
   cp .env.example .env
   ```
   Add your Supabase credentials:
   ```
   SUPABASE_URI=your_supabase_postgres_uri
   ```

3. **Start Ollama and pull the model**:
   ```bash
   ollama serve
   ollama pull llama3:3b
   ```

4. **Set up the environment and install dependencies**:
   ```bash
   make setup
   ```

## ğŸ¯ Usage

To run the project and ask a natural language question:
```bash
make run
```

Edit `main.py` to change the input question:
```python
question = "What is the neighborhood with the greatest number of people in Barcelona?"
```

## âš™ï¸ Makefile Commands

- `make setup` â€“ Create virtual environment and install all dependencies
- `make install` â€“ Install project dependencies
- `make run` â€“ Launch the app with the LLM agent
- `make clean` â€“ Remove Python cache and temporary files

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ main.py              # Main application script
â”œâ”€â”€ custom_prompt.txt    # Domain-specific prompt for the SQL agent
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Makefile             # Utility commands
â”œâ”€â”€ .env                 # Environment variables (user-provided)
```

## ğŸ“ Notes

- This setup uses the lightweight LLaMA 3B model for fast, local execution
- The SQL database must follow the schema defined in `custom_prompt.txt`
- Ensure Ollama is running before executing the model

## ğŸ¤ Contributing

Contributions are welcome! Feel free to fork the repo and open pull requests or issues.

## ğŸ“„ License

This project is under the MIT License â€“ see the [LICENSE](LICENSE) file for details.