{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Consistency Check\n",
                "\n",
                "This notebook checks if the number of neighborhoods in the processed data matches the input data for each city, indicator, and year."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import requests\n",
                "from io import StringIO\n",
                "from collections import defaultdict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    indicator_def_id  year  city_id  unique_geo_ids\n",
                        "0                  1  2019        1              73\n",
                        "1                  1  2020        1              73\n",
                        "2                  1  2020        2             131\n",
                        "3                  1  2021        1              73\n",
                        "4                  1  2021        2             131\n",
                        "5                  1  2022        1              73\n",
                        "6                  1  2022        2             131\n",
                        "7                  1  2023        1              73\n",
                        "8                  1  2023        2             131\n",
                        "9                  1  2024        2             131\n",
                        "10                 2  2019        1              73\n",
                        "11                 2  2020        1              73\n",
                        "12                 2  2020        2             131\n",
                        "13                 2  2021        1              73\n",
                        "14                 2  2021        2             131\n",
                        "15                 2  2022        2             131\n",
                        "16                 2  2023        2             131\n",
                        "17                 2  2024        2             131\n",
                        "18                 3  2019        1              73\n",
                        "19                 3  2020        1              73\n",
                        "20                 3  2021        1              73\n",
                        "21                 3  2022        1              73\n",
                        "22                 4  2019        1              73\n",
                        "23                 4  2020        1              73\n",
                        "24                 4  2021        1              73\n"
                    ]
                }
            ],
            "source": [
                "# Configure paths\n",
                "BASE_DIR = Path.cwd().parent.parent\n",
                "PROCESSED_FILES = {\n",
                "    \"barcelona\": BASE_DIR / \"data/processed/insert_ready_indicators_bcn.json\",\n",
                "    \"madrid\": BASE_DIR / \"data/processed/insert_ready_indicators_madrid.json\"\n",
                "}\n",
                "\n",
                "# Load files\n",
                "with open(PROCESSED_FILES['barcelona']) as f_bcn, open(PROCESSED_FILES['madrid']) as f_mad:\n",
                "    data_bcn = json.load(f_bcn)\n",
                "    data_mad = json.load(f_mad)\n",
                "\n",
                "# Convert to DataFrame\n",
                "df_bcn = pd.DataFrame(data_bcn)\n",
                "df_mad = pd.DataFrame(data_mad)\n",
                "\n",
                "# Combine both\n",
                "df_all = pd.concat([df_bcn, df_mad], ignore_index=True)\n",
                "\n",
                "# Group and count unique geo_id by indicator_def_id, year, city_id\n",
                "grouped = df_all.groupby(['indicator_def_id', 'year', 'city_id'])['geo_id'].nunique().reset_index()\n",
                "grouped.rename(columns={'geo_id': 'unique_geo_ids'}, inplace=True)\n",
                "\n",
                "# Show results\n",
                "print(grouped)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Registers in Barcelona: 1095\n",
                        "Registers in Madrid:    1310\n",
                        "TOTAL to insert:    2405\n"
                    ]
                }
            ],
            "source": [
                "# Count records in each DataFrame\n",
                "n_bcn = len(df_bcn)\n",
                "n_mad = len(df_mad)\n",
                "total = n_bcn + n_mad\n",
                "\n",
                "print(f\"Registers in Barcelona: {n_bcn}\")\n",
                "print(f\"Registers in Madrid:    {n_mad}\")\n",
                "print(f\"TOTAL to insert:    {total}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unique indicators: 4\n",
                        "Expected rows in view: 948\n"
                    ]
                }
            ],
            "source": [
                "n_indicators = df_all['indicator_def_id'].nunique()\n",
                "n_neighborhoods = 73 + 131  # 204\n",
                "n_districts = 10 + 21       # 31\n",
                "n_cities = 2\n",
                "\n",
                "expected_view_rows = n_indicators * (n_neighborhoods + n_districts + n_cities)\n",
                "\n",
                "print(f\"Unique indicators: {n_indicators}\")\n",
                "print(f\"Expected rows in view: {expected_view_rows}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Geo IDs in indicators: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]\n",
                        "Missing in indicators: []\n"
                    ]
                }
            ],
            "source": [
                "with open(PROCESSED_FILES['barcelona']) as f:\n",
                "    indicators = json.load(f)\n",
                "\n",
                "geo_ids = {i['geo_id'] for i in indicators}\n",
                "print(f\"Geo IDs in indicators: {sorted(geo_ids)}\")\n",
                "\n",
                "# Comparar con los geo_id reales\n",
                "from supabase import create_client\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "supabase = create_client(os.getenv(\"SUPABASE_URL\"), os.getenv(\"SUPABASE_SERVICE_KEY\"))\n",
                "res = supabase.table(\"neighbourhoods\").select(\"id\").eq(\"city_id\", 1).execute()\n",
                "neigh_ids = {n[\"id\"] for n in res.data}\n",
                "print(f\"Missing in indicators: {sorted(neigh_ids - geo_ids)}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Geo IDs in indicators: [74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204]\n",
                        "Missing in indicators: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]\n"
                    ]
                }
            ],
            "source": [
                "with open(PROCESSED_FILES['madrid']) as f:\n",
                "    indicators = json.load(f)\n",
                "\n",
                "geo_ids = {i['geo_id'] for i in indicators}\n",
                "print(f\"Geo IDs in indicators: {sorted(geo_ids)}\")\n",
                "\n",
                "# Comparar con los geo_id reales\n",
                "from supabase import create_client\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "supabase = create_client(os.getenv(\"SUPABASE_URL\"), os.getenv(\"SUPABASE_SERVICE_KEY\"))\n",
                "res = supabase.table(\"neighbourhoods\").select(\"id\").eq(\"city_id\", 1).execute()\n",
                "neigh_ids = {n[\"id\"] for n in res.data}\n",
                "print(f\"Missing in indicators: {sorted(neigh_ids - geo_ids)}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
